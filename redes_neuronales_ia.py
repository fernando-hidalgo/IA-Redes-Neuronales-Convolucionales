# -*- coding: utf-8 -*-
"""Redes neuronales IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zXJBC4cwwOaQEcTcR3oI30lRtBu0zToI
"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive
!unzip '/content/drive/MyDrive/train.zip' -d '/content/Data'
!pip install split_folders

# Commented out IPython magic to ensure Python compatibility.
import keras
import splitfolders
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip
from tensorflow.keras.optimizers import *
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.regularizers import *
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
from sklearn.metrics import confusion_matrix
from tensorflow.keras.applications.densenet import DenseNet121
import itertools
import os
import shutil
import random
import glob
import warnings
import matplotlib.pyplot as plt
warnings.simplefilter(action='ignore', category=FutureWarning)
# %matplotlib inline

os.makedirs('output')
os.makedirs('output/train')
os.makedirs('output/val')

splitfolders.ratio('Data', output='output', seed=1337, ratio=(0.9, 0.1))

dirname = os.path.join(os.getcwd(), 'output/train')
artists = next(os.walk(dirname))[1]
print(artists)

train_path = 'output/train'
valid_path = 'output/val'

train_batches = ImageDataGenerator( rescale = 1.0/255., rotation_range = 50, horizontal_flip = 'true', fill_mode='nearest').flow_from_directory(directory=train_path, target_size=(244,244), classes= artists, batch_size=10)

vaid_batches = ImageDataGenerator(rescale = 1.0/255.).flow_from_directory(directory=valid_path, target_size=(244,244), classes= artists, batch_size=10)

def plotImages(images_array):
  fig, axes = plt.subplots(1,10, figsize=(20,20))
  axes = axes.flatten()
  for img, ax in zip(images_array, axes):
    ax.imshow(img)
    ax.axis('off')
  plt.tight_layout()
  plt.show

imgs, labels = next(train_batches)
plotImages(imgs)
print(labels)

"""Modelo 1 - Red SIN regularización"""

model = Sequential([
        Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(244,244,3)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'),
        MaxPool2D(pool_size=(2,2), strides=2),
        Flatten(),
        Dense(units=500, activation='relu'),
        Dense(units=len(artists), activation='softmax'),
])

model.summary()
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x=train_batches, validation_data=vaid_batches, epochs=25, verbose=2)

print(history.history.keys())
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

model.save('/content/output/models/model1.h5')

"""Modelo 2 - Red con regularización, misma arquitectura que Modelo 1"""

model2 = Sequential([
        Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(244,244,3)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'),
        MaxPool2D(pool_size=(2,2), strides=2),
        Flatten(),
        Dense(units=500, activation='relu'),
        Dense(units=len(artists), activation='softmax'),
])

model2.summary()
model2.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history2 = model2.fit(x=train_batches, validation_data=vaid_batches, epochs=25, verbose=2)

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

model2.save('/content/output/models/model2.h5')

"""
Modelo 3 - Red con regularización, utilizando una arquitectura distinta"""

model3 = Sequential([
        Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(244,244,3)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),
        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'),
        MaxPool2D(pool_size=(2,2), strides=2),
        Flatten(),
        Dense(units=len(artists), activation='softmax'),
])
model3.summary()
model3.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history3 = model3.fit(x=train_batches, validation_data=vaid_batches, epochs=20, verbose=2)

import matplotlib.pyplot as plt
plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

model3.save('content/drive/MyDrive/model3.h5')